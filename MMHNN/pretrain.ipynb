{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a26631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwj/anaconda3/envs/zs/lib/python3.9/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: libcudart.so.10.2: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950000 50000\n",
      "Model001(\n",
      "  (gin): GINet(\n",
      "    (initial_norm): LayerNorm(55, affine=True, mode=graph)\n",
      "    (lin): Linear(in_features=55, out_features=300, bias=True)\n",
      "    (gnns): ModuleList(\n",
      "      (0-4): 5 x GINEConv()\n",
      "    )\n",
      "    (net_norms): ModuleList(\n",
      "      (0-4): 5 x LayerNorm(300, affine=True, mode=graph)\n",
      "    )\n",
      "    (batch_norms): ModuleList(\n",
      "      (0-4): 5 x BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (feat_lin): Linear(in_features=300, out_features=256, bias=True)\n",
      "    (out_lin): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0-1): 2 x SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  51%|█████     | 7568/14843 [35:44<24:42,  4.91it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Iteration: 100%|██████████| 14843/14843 [1:11:07<00:00,  3.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss: 8.08524249858197 valid_xent_loss: 7.939001018095231 valid_motif_loss: 0.7312074004298696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  40%|███▉      | 312/781 [02:23<04:34,  1.71it/s]"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/dwj/WWW/DDIsubgraph/pretrain\")\n",
    "from dataset.dataset import MoleculeDatasetWrapper\n",
    "from models.model import Model001\n",
    "from loss_utils.nt_xent import NTXentLoss\n",
    "from loss_utils.weighted_nt_xent import Weighted_NTXentLoss\n",
    "from loss_utils.motif_loss import Motif_Loss\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, valid_loader, optimizer, device, gama):\n",
    "    model.train()\n",
    "    xent_list = []\n",
    "    motif_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
    "        batch=batch.to(device)\n",
    "        out_global, motif_embeddings, weight, weight_mask, out_sub, motif_num = model(batch)\n",
    "        nt_xent_criterion = NTXentLoss(device, temperature=0.1, use_cosine_similarity=True, lambda_1=0.5, lambda_2=0.5)\n",
    "        nt_xent_criterion_weighted = Weighted_NTXentLoss(device, temperature=0.1, use_cosine_similarity=True, lambda_1=0.5, lambda_2=0.5)\n",
    "        motif_criterion = Motif_Loss(device, use_cosine_similarity=True)\n",
    "\n",
    "        out_global = F.normalize(out_global, dim=1)\n",
    "        motif_embeddings = F.normalize(motif_embeddings, dim=1)\n",
    "        if args.weight==1:\n",
    "            xent_loss = nt_xent_criterion_weighted(out_global, motif_embeddings, weight_mask)\n",
    "        else:\n",
    "            xent_loss=nt_xent_criterion(out_global, motif_embeddings)\n",
    "        motif_loss = motif_criterion(out_sub, motif_num)\n",
    "        loss = xent_loss+gama*motif_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        xent_list.append(xent_loss.item())\n",
    "        motif_list.append(motif_loss.item())\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    train_xent_loss = sum(xent_list)/len(xent_list)\n",
    "    train_motif_loss = sum(motif_list)/len(motif_list)\n",
    "    train_loss = sum(loss_list)/len(loss_list)\n",
    "    print(\"train_loss:\",train_loss,\"train_xent_loss:\",train_xent_loss,\"train_motif_loss:\",train_motif_loss)\n",
    "\n",
    "    valid_loss = validate(args,model,valid_loader,device,gama)\n",
    "    return train_loss, valid_loss\n",
    "\n",
    "\n",
    "def validate(args,model, valid_loader,device,gama):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        xent_list = []\n",
    "        motif_list = []\n",
    "        loss_list = []\n",
    "        for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "            batch = batch.to(device)\n",
    "            out_global, motif_embeddings, weight, weight_mask, out_sub, motif_num = model(batch)\n",
    "            nt_xent_criterion = NTXentLoss(device, temperature=0.1, use_cosine_similarity=True, lambda_1=0.5,\n",
    "                                           lambda_2=0.5)\n",
    "            nt_xent_criterion_weighted = Weighted_NTXentLoss(device, temperature=0.1, use_cosine_similarity=True,\n",
    "                                                             lambda_1=0.5, lambda_2=0.5)\n",
    "            motif_criterion = Motif_Loss(device, use_cosine_similarity=True)\n",
    "\n",
    "            out_global = F.normalize(out_global, dim=1)\n",
    "            motif_embeddings = F.normalize(motif_embeddings, dim=1)\n",
    "            if args.weight == 1:\n",
    "                xent_loss = nt_xent_criterion_weighted(out_global, motif_embeddings, weight_mask)\n",
    "            else:\n",
    "                xent_loss = nt_xent_criterion(out_global, motif_embeddings)\n",
    "            motif_loss = motif_criterion(out_sub, motif_num)\n",
    "            loss = xent_loss + gama * motif_loss\n",
    "\n",
    "            xent_list.append(xent_loss.item())\n",
    "            motif_list.append(motif_loss.item())\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "        valid_xent_loss = sum(xent_list) / len(xent_list)\n",
    "        valid_motif_loss = sum(motif_list) / len(motif_list)\n",
    "        valid_loss = sum(loss_list)/len(loss_list)\n",
    "        print(\"valid_loss:\", valid_loss, \"valid_xent_loss:\", valid_xent_loss, \"valid_motif_loss:\", valid_motif_loss)\n",
    "    model.train()\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "    parser.add_argument('--device', type=int, default=3,\n",
    "                        help='which gpu to use if any (default: 0)')\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help=' inputbatch size for training (default: 1024)')\n",
    "    parser.add_argument('--dataset', type=str, default='/home/dwj/WWW/DDIsubgraph/pretrain/pubchem-10m-clean-100w.txt',\n",
    "                        help='root directory of dataset.')\n",
    "\n",
    "    parser.add_argument('--valid_size', type=float, default=0.05,\n",
    "                        help='valid_size (default: 0.2)')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help=' the number of workers to load data (default: 8)')\n",
    "\n",
    "\n",
    "    parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5).')\n",
    "    parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                        help='embedding dimensions (default: 300)')\n",
    "    parser.add_argument('--feat_dim', type=int, default=256,\n",
    "                        help='embedding dimensions (default: 256)')\n",
    "    parser.add_argument('--dropout_gin', type=float, default=0,\n",
    "                        help='dropout ratio (default: 0.2)')\n",
    "    parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                        help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "    parser.add_argument('--N', type=int, default=2,\n",
    "                        help='num layer of transformer encoder')\n",
    "    parser.add_argument('--d_model', type=int, default=256,\n",
    "                        help='embedding dimensions (default: 256)')\n",
    "    parser.add_argument('--d_ff', type=int, default=1024,\n",
    "                        help='embedding dimensions (default: 1024)')\n",
    "    parser.add_argument('--h', type=int, default=8,\n",
    "                        help='heads of transformer encoder(default: 8)')\n",
    "    parser.add_argument('--dropout_encoder', type=float, default=0.1,\n",
    "                        help='dropout ratio (default: 0.1)')\n",
    "    parser.add_argument('--weight', type=int, default=1,\n",
    "                        help='weight or not')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "\n",
    "    parser.add_argument('--decay', type=float, default=0.00001,\n",
    "                        help='weight decay (default: 0)')\n",
    "    parser.add_argument('--lr', type=float, default=0.0005,\n",
    "                        help='learning rate (default: 0.001)')\n",
    "\n",
    "\n",
    "    parser.add_argument('--output_model_file', type=str, default='/home/dwj/WWW/DDIsubgraph/pretrain/save_model/pretrain/motif_loss+weight',\n",
    "                        help='filename to output the pre-trained model')\n",
    "    parser.add_argument('--gama', type=float, default=0.2, help='weight of motif_loss')\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "    dataset = MoleculeDatasetWrapper(args.batch_size, args.num_workers, args.valid_size, args.dataset)   # dataset：一个txt文件路径，里面村的是smiles\n",
    "    train_loader, valid_loader = dataset.get_data_loaders()  # 导入数据集，编码，在dataset里\n",
    "\n",
    "    model = Model001(num_layer=args.num_layer, emb_dim=args.emb_dim, feat_dim=args.feat_dim,\n",
    "                     dropout_gin=args.dropout_gin, pool=args.graph_pooling, device=device,\n",
    "                     N=args.N, d_model=args.d_model, d_ff=args.d_ff, h=args.h,\n",
    "                     dropout_encoder=args.dropout_encoder).to(device)         # model\n",
    "    print(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs - 9, eta_min=0, last_epoch=-1)\n",
    "\n",
    "    min_loss = 1000000\n",
    "    train_loss_list=[]\n",
    "    valid_loss_list=[]\n",
    "    result_dir=args.output_model_file  # 存的输出模型的路径\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    a=validate(args, model, train_loader, device, args.gama)\n",
    "    b=validate(args, model, valid_loader, device, args.gama)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(\"====epoch \" + str(epoch))\n",
    "\n",
    "        epoch_start=time.time()\n",
    "        train_loss,valid_loss = train(args, model, train_loader, valid_loader, optimizer, device, args.gama)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        epoch_end=time.time()\n",
    "\n",
    "        print(\"epoch:\", epoch, \"time:\", epoch_end-epoch_start, \"s\")\n",
    "\n",
    "        if not args.output_model_file == \"\":\n",
    "            torch.save(model.state_dict(), result_dir + \"/pretrain_model_epoch_\" + str(epoch) + \".pth\")   # 保存模型\n",
    "        if valid_loss < min_loss:\n",
    "            min_loss = valid_loss\n",
    "            torch.save(model.state_dict(), result_dir + \"/pretrain_motif_model_min_loss_\" + \".pth\")\n",
    "\n",
    "        if epoch >= 10:\n",
    "            print(\"warmup\")\n",
    "            scheduler.step()\n",
    "\n",
    "    plt.plot(train_loss_list)\n",
    "    plt.savefig(result_dir+'/train_loss_list.png')   #loss下降图\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(valid_loss_list)\n",
    "    plt.savefig(result_dir + '/valid_loss_list.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc89902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx=[[1,2,3],[4,5,6],[7,8,9,10]]\n",
    "curr_num=0\n",
    "curr_idx = np.array(list(idx),dtype=object)+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f626bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[7,8,9,10]\n",
    "s=idx+5\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f50302",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpretrain_result()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.pretrain_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f3ae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500 500\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=3,\n",
    "                    help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--batch_size', type=int, default=64,\n",
    "                    help=' inputbatch size for training (default: 1024)')\n",
    "parser.add_argument('--dataset', type=str, default='/home/dwj/WWW/DDIsubgraph/pretrain/pubchem-10m-clean-small.txt',\n",
    "                    help='root directory of dataset.')\n",
    "\n",
    "parser.add_argument('--valid_size', type=float, default=0.05,\n",
    "                    help='valid_size (default: 0.2)')\n",
    "parser.add_argument('--num_workers', type=int, default=8,\n",
    "                    help=' the number of workers to load data (default: 8)')\n",
    "\n",
    "\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--feat_dim', type=int, default=256,\n",
    "                    help='embedding dimensions (default: 256)')\n",
    "parser.add_argument('--dropout_gin', type=float, default=0,\n",
    "                    help='dropout ratio (default: 0.2)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                    help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--N', type=int, default=2,\n",
    "                    help='num layer of transformer encoder')\n",
    "parser.add_argument('--d_model', type=int, default=256,\n",
    "                    help='embedding dimensions (default: 256)')\n",
    "parser.add_argument('--d_ff', type=int, default=1024,\n",
    "                    help='embedding dimensions (default: 1024)')\n",
    "parser.add_argument('--h', type=int, default=8,\n",
    "                    help='heads of transformer encoder(default: 8)')\n",
    "parser.add_argument('--dropout_encoder', type=float, default=0.1,\n",
    "                    help='dropout ratio (default: 0.1)')\n",
    "parser.add_argument('--weight', type=int, default=1,\n",
    "                    help='weight or not')\n",
    "\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "\n",
    "parser.add_argument('--decay', type=float, default=0.00001,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--lr', type=float, default=0.0005,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "\n",
    "\n",
    "parser.add_argument('--output_model_file', type=str, default='/home/dwj/WWW/DDIsubgraph/pretrain/save_model/pretrain/motif_loss+weight',\n",
    "                    help='filename to output the pre-trained model')\n",
    "parser.add_argument('--gama', type=float, default=0.2, help='weight of motif_loss')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "dataset = MoleculeDatasetWrapper(args.batch_size, args.num_workers, args.valid_size, args.dataset)   # dataset：一个txt文件路径，里面村的是smiles\n",
    "train_loader, valid_loader = dataset.get_data_loaders()  # 导入数据集，编码，在dataset里\n",
    "\n",
    "model = Model001(num_layer=args.num_layer, emb_dim=args.emb_dim, feat_dim=args.feat_dim,\n",
    "                 dropout_gin=args.dropout_gin, pool=args.graph_pooling, device=device,\n",
    "                 N=args.N, d_model=args.d_model, d_ff=args.d_ff, h=args.h,\n",
    "                 dropout_encoder=args.dropout_encoder).to(device)         # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc50e83f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pretrain_result() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrain_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: pretrain_result() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "model.pretrain_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc37ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth= \"/home/dwj/WWW/DDIsubgraph/pretrain/save_model/pretrain/motif_loss+weight/pretrain_model_epoch_99.pth\" \n",
    "checkpoint = torch.load(pth)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80338e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|          | 1/148 [00:03<09:29,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   3%|▎         | 5/148 [00:04<01:22,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   5%|▌         | 8/148 [00:04<00:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   9%|▉         | 13/148 [00:07<00:50,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  11%|█         | 16/148 [00:07<00:33,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 16, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  11%|█         | 16/148 [00:09<01:16,  1.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m      2\u001b[0m        batch\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m        a,b\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrain_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m        \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      5\u001b[0m        \u001b[38;5;28mprint\u001b[39m(b\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/WWW/DDIsubgraph/pretrain/models/model.py:63\u001b[0m, in \u001b[0;36mModel001.pretrain_result\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpretrain_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 63\u001b[0m     h_global, out_global, h_sub, out_sub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_global,out_sub\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/WWW/DDIsubgraph/pretrain/models/gnn.py:118\u001b[0m, in \u001b[0;36mGINet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m data\u001b[38;5;241m.\u001b[39mmax_len:\n\u001b[1;32m    116\u001b[0m         pad_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad\u001b[38;5;241m.\u001b[39mrepeat_interleave(data\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;241m-\u001b[39m idx, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m         h_sub \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((h_sub[:idx \u001b[38;5;241m+\u001b[39m data\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;241m*\u001b[39m k, :], pad_tensor,\n\u001b[0;32m--> 118\u001b[0m                            h_sub[idx \u001b[38;5;241m+\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m \u001b[38;5;241m*\u001b[39m k:, :]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    119\u001b[0m     k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    121\u001b[0m h_sub\u001b[38;5;241m=\u001b[39mh_sub\u001b[38;5;241m.\u001b[39mview(h_global\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), data\u001b[38;5;241m.\u001b[39mmax_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_dim)\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/torch_geometric/data/data.py:441\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " for step, batch in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
    "        batch=batch.to(device)\n",
    "        a,b=model.pretrain_result(batch)\n",
    "        print(a.size())\n",
    "        print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cf69b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zs] *",
   "language": "python",
   "name": "conda-env-zs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
